# Handwritten-digits-Classifier

In this project we will first of all consider the complexity behind image classification, then we will evaluate limitations of traditional machine learning models for image classification and finally we will develop few different neural networks for image classification.
Image classification is a hard task for different reasons: first of all the image in a training set is high dimensional, considering that each pixel in an image is a feature; morevorer, sometimes we lose details which can be useful during the training process since the images are often downsampled. Finally the features in an image do not have linear or nonlinear relationship that can be learned with a traditional model like linear or logistic regression (e.g. in grayscale, each pixel is just represented as a brightness value ranging from 0 to 256). Thanks to it's ability in learning hierarchical representations, deep learning is effective in image classification. Indeed each layer will learn a specific intermediate representation and each successive layer uses weights from previous layers to try to learn more complex representations.
The dataset we will use for this project is the one stored in skleran.datasets, that can be accessed by the function load_digits() and that is a copy of the hand-written digits dataset from UCI.
